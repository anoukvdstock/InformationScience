{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1: Onegram Counter\n",
    "You probably know about Google Book's Ngram Viewer: when you enter phrases into it, it displays a graph showing how those phrases have occurred in a corpus of books (e.g., \"British English\", \"English Fiction\", \"French\") over the selected years.\n",
    "\n",
    "Your assignment for this course is something similar: build a Python function that can take the file data/corpus.txt (UTF-8 encoded) from this repo as an argument and print a count of the 100 most frequent 1-grams (i.e. single words).\n",
    "\n",
    "In essence the job is to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 11852), ('', 5952), ('of', 5768), ('and', 5264), ('to', 4027), ('a', 3980), ('in', 3548), ('that', 2336), ('his', 2061), ('it', 1517), ('as', 1490), ('i', 1488), ('with', 1460), ('he', 1448), ('is', 1400), ('was', 1393), ('for', 1337), ('but', 1319), ('all', 1148), ('at', 1116), ('this', 1063), ('by', 1042), ('from', 944), ('not', 933), ('be', 863), ('on', 850), ('so', 763), ('you', 718), ('one', 694), ('have', 658), ('had', 647), ('or', 638), ('were', 551), ('they', 547), ('are', 504), ('some', 498), ('my', 484), ('him', 480), ('which', 478), ('their', 478), ('upon', 475), ('an', 473), ('like', 470), ('when', 458), ('whale', 456), ('into', 452), ('now', 437), ('there', 415), ('no', 414), ('what', 413), ('if', 404), ('out', 397), ('up', 380), ('we', 379), ('old', 365), ('would', 350), ('more', 348), ('been', 338), ('over', 324), ('only', 322), ('then', 312), ('its', 307), ('such', 307), ('me', 307), ('other', 301), ('will', 300), ('these', 299), ('down', 270), ('any', 269), ('than', 262), ('has', 257), ('very', 252), ('though', 245), ('yet', 245), ('those', 242), ('must', 238), ('them', 237), ('her', 237), ('do', 234), ('about', 234), ('said', 233), ('ye', 232), ('who', 231), ('still', 229), ('great', 229), ('most', 228), ('man', 220), ('two', 219), ('seemed', 216), ('long', 214), ('your', 213), ('before', 212), ('it,', 210), ('thou', 210), ('ship', 209), ('after', 208), ('white', 207), ('did', 202), ('little', 201), ('him,', 194)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import os\n",
    "\n",
    "def onegrams(file):\n",
    "    with open(file, 'r') as corpus:\n",
    "        text = corpus.read()\n",
    "        # .casefold() is better than .lower() here\n",
    "        # https://www.programiz.com/python-programming/methods/string/casefold\n",
    "        normalize = text.casefold()\n",
    "        words = normalize.split(' ')\n",
    "        count = Counter(words) \n",
    "        return count\n",
    "\n",
    "ngram_viewer = onegrams(r\"C:\\Users\\anouk\\OneDrive\\Documenten\\GitHub\\InformationScience\\course\\data\\corpus.txt\")\n",
    "print(ngram_viewer.most_common(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, you can't use the `collections` library. :-)\n",
    "\n",
    "Moreover, try to think about what else may be suboptimal in this example. For instance, in this code all of the text is loaded into memory in one time (with the `read()` method). What would happen if we tried this on a really big text file? \n",
    "\n",
    "**Most importantly, the count is also wrong**. Check by counting in an editor, for instance, and try to find out why.\n",
    "\n",
    "If this is an easy task for you, you can also think about the graphical representation of the 1-gram count.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> SOLUTION:\n",
    "\n",
    "Not quite there yet but closer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 14400),\n",
       " ('of', 6645),\n",
       " ('and', 6403),\n",
       " ('a', 4666),\n",
       " ('to', 4642),\n",
       " ('in', 4161),\n",
       " ('that', 2950),\n",
       " ('his', 2520),\n",
       " ('it', 2388),\n",
       " ('i', 1944),\n",
       " ('but', 1781),\n",
       " ('he', 1747),\n",
       " ('is', 1728),\n",
       " ('as', 1728),\n",
       " ('with', 1727),\n",
       " ('was', 1638),\n",
       " ('for', 1623),\n",
       " ('all', 1485),\n",
       " ('this', 1405),\n",
       " ('at', 1323),\n",
       " ('by', 1225),\n",
       " ('not', 1141),\n",
       " ('from', 1102),\n",
       " ('on', 1065),\n",
       " ('be', 1050),\n",
       " ('so', 1050),\n",
       " ('him', 1044),\n",
       " ('whale', 956),\n",
       " ('you', 916),\n",
       " ('one', 901),\n",
       " ('had', 777),\n",
       " ('have', 770),\n",
       " ('there', 767),\n",
       " ('now', 766),\n",
       " ('or', 758),\n",
       " ('were', 682),\n",
       " ('they', 659),\n",
       " ('which', 642),\n",
       " ('their', 619),\n",
       " ('then', 618),\n",
       " ('some', 617),\n",
       " ('me', 610),\n",
       " ('are', 608),\n",
       " ('when', 598),\n",
       " ('an', 593),\n",
       " ('my', 586),\n",
       " ('no', 577),\n",
       " ('like', 576),\n",
       " ('upon', 565),\n",
       " ('what', 545),\n",
       " ('into', 524),\n",
       " ('out', 520),\n",
       " ('up', 509),\n",
       " ('more', 509),\n",
       " ('if', 497),\n",
       " ('its', 465),\n",
       " ('them', 459),\n",
       " ('we', 457),\n",
       " ('old', 440),\n",
       " ('man', 435),\n",
       " ('would', 428),\n",
       " ('ye', 421),\n",
       " ('ahab', 417),\n",
       " ('other', 416),\n",
       " ('been', 415),\n",
       " ('over', 405),\n",
       " ('these', 403),\n",
       " ('will', 391),\n",
       " ('whales', 389),\n",
       " ('ship', 383),\n",
       " ('sea', 379),\n",
       " ('only', 377),\n",
       " ('such', 372),\n",
       " ('though', 364),\n",
       " ('down', 361),\n",
       " ('any', 341),\n",
       " ('yet', 339),\n",
       " ('who', 334),\n",
       " ('time', 328),\n",
       " ('her', 323),\n",
       " ('very', 320),\n",
       " ('long', 316),\n",
       " ('about', 312),\n",
       " ('than', 310),\n",
       " ('still', 308),\n",
       " ('do', 307),\n",
       " ('those', 307),\n",
       " ('great', 303),\n",
       " ('before', 297),\n",
       " ('captain', 294),\n",
       " ('has', 293),\n",
       " ('said', 293),\n",
       " ('here', 290),\n",
       " ('two', 284),\n",
       " ('must', 283),\n",
       " ('most', 282),\n",
       " ('seemed', 281),\n",
       " ('last', 275),\n",
       " ('head', 269),\n",
       " ('see', 264)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "from operator import itemgetter\n",
    "\n",
    "def onegrams(file, mostfreq=100):\n",
    "    \"\"\"Returns n (mostfreq argument) most frequent words in a file\"\"\"\n",
    "    # initialize output variable for frequency count\n",
    "    counts = {} \n",
    "\n",
    "    with open(file, \"r\", encoding=\"utf8\") as corpus:\n",
    "        for line in corpus:\n",
    "            # remove punctuation from lines\n",
    "            # this solves problems like \"the\" != \"the,\"\n",
    "            # downside: will turn \"it's\" into \"its\"\n",
    "            remove_noise = line.translate(line.maketrans(\"\", \"\", string.punctuation))\n",
    "            # removed the argument from split function, otherwise new lines are not taken into account when splitting\n",
    "            normalized_words = remove_noise.casefold().split()\n",
    "\n",
    "            # update frequency of each word in the dictionary\n",
    "            for word in normalized_words:\n",
    "                try:\n",
    "                    counts[word] += 1\n",
    "                except KeyError:\n",
    "                    counts[word] = 1\n",
    "                    \n",
    "    # sort frequency dictionary, make into list and slice to show most common    \n",
    "    return list(sorted(counts.items(), key=itemgetter(1), reverse=True))[:mostfreq]\n",
    "\n",
    "onegrams(r\"C:\\Users\\anouk\\OneDrive\\Documenten\\GitHub\\InformationScience\\course\\data\\corpus.txt\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
